import os
import cv2
import subprocess
import argparse
from pathlib import Path

def extract_video_from_jpeg(jpeg_path, output_video_path):
    """ä»Žå°ç±³åŠ¨æ€ç…§ç‰‡çš„ .jpg æ–‡ä»¶ä¸­æå–å†…åµŒè§†é¢‘æ•°æ®ï¼Œå¹¶ä½¿ç”¨ ffmpeg ä¿®å¤ fragmented MP4 ç»“æž„ã€‚"""
    try:
        with open(jpeg_path, 'rb') as f:
            data = f.read()

        marker = b'\xFF\xD9'
        marker_pos = data.find(marker)

        if marker_pos == -1:
            print(f"âš ï¸ è­¦å‘Š: åœ¨æ–‡ä»¶ '{jpeg_path}' ä¸­æœªæ‰¾åˆ° JPEG ç»“æŸæ ‡è®°ã€‚è·³è¿‡æ­¤æ–‡ä»¶ã€‚")
            return False

        video_data = data[marker_pos + len(marker):]

        if not video_data:
            print(f"âš ï¸ è­¦å‘Š: åœ¨æ–‡ä»¶ '{jpeg_path}' çš„ JPEG ç»“æŸæ ‡è®°åŽæœªæ‰¾åˆ°è§†é¢‘æ•°æ®ã€‚è·³è¿‡æ­¤æ–‡ä»¶ã€‚")
            return False

        # ä¿å­˜åŽŸå§‹æå–çš„è§†é¢‘
        with open(output_video_path, 'wb') as f:
            f.write(video_data)

        print(f"ðŸ’¾ å·²æå–åŽŸå§‹è§†é¢‘: '{output_video_path}'")

        # --- Step 1: å°è¯•ç”¨ -f mp4 + -ignore_editlist ä¿®å¤ fragment ---
        fixed_step1 = output_video_path.replace(".mp4", "_step1.mp4")
        cmd1 = [
            'ffmpeg',
            '-f', 'mp4',
            '-ignore_editlist', '1',  # å¿½ç•¥ç¼–è¾‘åˆ—è¡¨ï¼Œå¸¸ç”¨äºŽä¿®å¤ fMP4
            '-i', output_video_path,
            '-c', 'copy',             # å…ˆä¸è½¬ç ï¼Œåªä¿®å¤ç»“æž„
            '-movflags', 'faststart',
            '-y',
            fixed_step1
        ]

        result1 = subprocess.run(cmd1, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        if result1.returncode == 0:
            print(f"ðŸ”§ æ­¥éª¤1ä¿®å¤æˆåŠŸ: '{fixed_step1}'")
            # --- Step 2: é‡æ–°ç¼–ç ç¡®ä¿å…¼å®¹æ€§ ---
            fixed_final = output_video_path.replace(".mp4", "_fixed.mp4")
            cmd2 = [
                'ffmpeg',
                '-i', fixed_step1,
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-crf', '23',
                '-c:a', 'aac',
                '-b:a', '128k',
                '-movflags', 'faststart',
                '-y',
                fixed_final
            ]
            result2 = subprocess.run(cmd2, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            if result2.returncode == 0:
                print(f"âœ… æœ€ç»ˆç¼–ç æˆåŠŸ: '{fixed_final}'")
                # æ›¿æ¢åŽŸæ–‡ä»¶
                os.remove(output_video_path)
                os.remove(fixed_step1)  # æ¸…ç†ä¸­é—´æ–‡ä»¶
                os.rename(fixed_final, output_video_path)
                return True
            else:
                print(f"âŒ æ­¥éª¤2ç¼–ç å¤±è´¥: {result2.stderr.decode('utf-8', errors='ignore')}")
        else:
            print(f"âŒ æ­¥éª¤1ä¿®å¤å¤±è´¥ï¼Œå°è¯•ç›´æŽ¥å¼ºåˆ¶è½¬ç ...")

        # --- å¤‡ç”¨æ–¹æ¡ˆï¼šå¼ºåˆ¶æŒ‡å®šæ ¼å¼ + å¿½ç•¥ moov + ä½¿ç”¨ copyts ---
        fixed_fallback = output_video_path.replace(".mp4", "_fallback.mp4")
        cmd_fallback = [
            'ffmpeg',
            '-f', 'mp4',
            '-ignore_editlist', '1',
            '-fflags', '+genpts',     # ç”Ÿæˆç¼ºå¤±çš„æ—¶é—´æˆ³
            '-i', output_video_path,
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-movflags', 'faststart',
            '-y',
            fixed_fallback
        ]
        result_fb = subprocess.run(cmd_fallback, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result_fb.returncode == 0:
            print(f"âœ… å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸ: '{fixed_fallback}'")
            os.remove(output_video_path)
            os.rename(fixed_fallback, output_video_path)
            return True
        else:
            print(f"âŒ å¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {result_fb.stderr.decode('utf-8', errors='ignore')}")

        return False

    except Exception as e:
        print(f"ðŸ’¥ æå–æˆ–ç¼–ç è§†é¢‘ '{jpeg_path}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

        # --- ç»ˆæžå…œåº•ï¼šå½“ä½œåŽŸå§‹ H.264 è£¸æµå¤„ç† ---
        print("ðŸ”„ ç»ˆæžå…œåº•ï¼šå°è¯•ä½œä¸º h264 è£¸æµå¤„ç†...")
        fixed_last_resort = output_video_path.replace(".mp4", "_last_resort.mp4")
        cmd_last = [
            'ffmpeg',
            '-f', 'h264',          # å¼ºåˆ¶å½“ä½œè£¸æµ
            '-i', output_video_path,
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '23',
            '-movflags', 'faststart',
            '-y',
            fixed_last_resort
        ]
        result_last = subprocess.run(cmd_last, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result_last.returncode == 0:
            print(f"âœ… ç»ˆæžå…œåº•æˆåŠŸ: '{fixed_last_resort}'")
            os.remove(output_video_path)
            os.rename(fixed_last_resort, output_video_path)
            return True
        else:
            print(f"âŒ ç»ˆæžå…œåº•å¤±è´¥: {result_last.stderr.decode('utf-8', errors='ignore')}")


def extract_and_filter_frames(video_path, output_folder, min_blur_threshold, detect_faces_flag, keep_blur_info):
    """
    ä»Žè§†é¢‘æ–‡ä»¶ä¸­é€å¸§æå–å›¾ç‰‡ï¼Œå¹¶æ ¹æ®æ¨¡ç³Šåº¦å’Œäººè„¸æ£€æµ‹è¿›è¡Œè¿‡æ»¤ã€‚
    """
    # å¥å£®æ€§æ£€æŸ¥
    if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:
        print(f"âŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ '{video_path}' ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
        return False

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ '{video_path}' è¿›è¡Œå¸§æå–ã€‚")
        return False

    # åˆ›å»ºè¾“å‡ºç›®å½•å’Œ filtered_out å­ç›®å½•
    os.makedirs(output_folder, exist_ok=True)
    filtered_out_dir = os.path.join(output_folder, "filtered_out")
    if not keep_blur_info:
        os.makedirs(filtered_out_dir, exist_ok=True)

    frame_count = 0
    saved_count = 0
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') if detect_faces_flag else None

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

        has_face = True
        if detect_faces_flag:
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
            has_face = len(faces) > 0

        frame_filename = f"frame_{frame_count:04d}.jpg"
        save_path = os.path.join(output_folder, frame_filename)

        reason = []
        if laplacian_var < min_blur_threshold:
            reason.append(f"æ¨¡ç³Š (Blur: {laplacian_var:.2f})")
        if detect_faces_flag and not has_face:
            reason.append("æ— äººè„¸")

        if reason:
            if keep_blur_info:
                cv2.imwrite(save_path, frame)
                print(f"âš ï¸  ä¿ç•™ä½†æ ‡æ³¨: {frame_filename} (åŽŸå› : {'; '.join(reason)})")
            else:
                cv2.imwrite(os.path.join(filtered_out_dir, frame_filename), frame)
                print(f"ðŸ—‘ï¸  å‰”é™¤å¸§: {frame_filename} (åŽŸå› : {'; '.join(reason)})")
        else:
            cv2.imwrite(save_path, frame)
            print(f"âœ… ä¿ç•™å¸§: {frame_filename} (Blur: {laplacian_var:.2f})")
            saved_count += 1

    cap.release()
    print(f"ðŸ“Š æœ¬è§†é¢‘å…±æå– {frame_count} å¸§ï¼Œä¿ç•™ {saved_count} å¸§ã€‚")
    return True


def process_motion_photo(jpeg_path, base_output_folder, config):
    """å¤„ç†å•ä¸ªå°ç±³åŠ¨æ€ç…§ç‰‡æ–‡ä»¶"""
    filename = Path(jpeg_path).stem
    output_folder = os.path.join(base_output_folder, filename)
    temp_video_path = os.path.join(base_output_folder, f"{filename}_temp_extracted.mp4")

    print(f"\nðŸ“¦ æ­£åœ¨å¤„ç†: {jpeg_path}")

    if not extract_video_from_jpeg(jpeg_path, temp_video_path):
        print(f"âŒ è§†é¢‘æå–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶ã€‚")
        return False

    if not extract_and_filter_frames(
        temp_video_path,
        output_folder,
        config['blur_threshold'],
        config['detect_faces'],
        config['keep_blur_info']
    ):
        print(f"âŒ å¸§æå–å¤±è´¥ã€‚")
        return False

    # æ¸…ç†ä¸´æ—¶è§†é¢‘æ–‡ä»¶
    try:
        os.remove(temp_video_path)
        print(f"ðŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_video_path}")
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {temp_video_path}: {e}")

    return True


def main(input_dir, output_dir, config):
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å°ç±³åŠ¨æ€ç…§ç‰‡"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    jpeg_files = list(input_path.glob("*.jpg")) + list(input_path.glob("*.jpeg"))
    total_files = len(jpeg_files)

    if total_files == 0:
        print(f"âš ï¸  åœ¨ '{input_dir}' ä¸­æœªæ‰¾åˆ°ä»»ä½• .jpg æˆ– .jpeg æ–‡ä»¶ã€‚")
        return

    print(f"ðŸ“ å¼€å§‹æ‰¹é‡å¤„ç† '{input_dir}' å†…çš„åŠ¨æ€ç…§ç‰‡...")
    print(f"ðŸ“¤ ç»“æžœå°†ä¿å­˜åˆ° '{output_dir}'")
    print(f"âš™ï¸  é…ç½®: æ¨¡ç³Šé˜ˆå€¼={config['blur_threshold']}, æ£€æµ‹äººè„¸={config['detect_faces']}, ä¿ç•™æ¨¡ç³Šä¿¡æ¯={config['keep_blur_info']}")

    processed_count = 0
    for jpeg_file in jpeg_files:
        if process_motion_photo(str(jpeg_file), str(output_path), config):
            processed_count += 1

    print(f"\nðŸŽ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† {processed_count} / {total_files} ä¸ªåŠ¨æ€ç…§ç‰‡ã€‚")
    print(f"ðŸ“‚ è¯·åœ¨ '{output_dir}' ç›®å½•ä¸‹æŸ¥çœ‹æå–å’Œè¿‡æ»¤åŽçš„å¸§å›¾ç‰‡ã€‚")
    print(f"ðŸ—‘ï¸  è¢«å‰”é™¤çš„å¸§ä½äºŽæ¯ä¸ªç…§ç‰‡æ–‡ä»¶å¤¹ä¸‹çš„ 'filtered_out' å­ç›®å½•ä¸­ã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä»Žå°ç±³åŠ¨æ€ç…§ç‰‡ä¸­æå–è§†é¢‘å¸§å¹¶è¿‡æ»¤æ¨¡ç³Š/æ— äººè„¸å¸§")
    parser.add_argument("input", help="è¾“å…¥ç›®å½•è·¯å¾„ï¼ŒåŒ…å« .jpg åŠ¨æ€ç…§ç‰‡")
    parser.add_argument("output", help="è¾“å‡ºç›®å½•è·¯å¾„ï¼Œä¿å­˜æå–çš„å¸§")
    parser.add_argument("--blur-threshold", type=float, default=100.0, help="æ¨¡ç³Šé˜ˆå€¼ (é»˜è®¤: 100.0)")
    parser.add_argument("--no-face-detect", action="store_true", help="ç¦ç”¨äººè„¸æ£€æµ‹")
    parser.add_argument("--keep-blur-info", action="store_true", help="ä¿ç•™æ¨¡ç³Šå¸§ï¼ˆæ·»åŠ æ ‡æ³¨ï¼‰ï¼Œä¸ç§»å…¥ filtered_out")

    args = parser.parse_args()

    config = {
        'blur_threshold': args.blur_threshold,
        'detect_faces': not args.no_face_detect,
        'keep_blur_info': args.keep_blur_info
    }

    main(args.input, args.output, config)
